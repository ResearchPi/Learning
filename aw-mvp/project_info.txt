User Input (Professor Name, School)

Scraping will not be used, but public apis will be:
arXiv (have to include "Thank you to arXiv for use of its open access interoperability.")
PubMed (NCBI API)
Google Scholar (will be using scholarly, no official API)
DOAJ (found)
Semantic Scholar
Zenodo 
Crossref

NLP Model
summarize each research paper from the links scraped into keywords for domain of the professor 
    (e.g. Dr. Pingkun Yan - Medical Imaging, Computer Vision, etc.)
After getting information of the papers, use NLP-base kyword Extraction
-KeyBERT
-TextRank
-YAKE
-spaCy

LLM Model
summarize all the keywords, background information into a json file (or some other format)

summarize the background information, education, position, contact info of the professor
Google Scholar Profile
LinkedIn Profile
News Publications about Professor
Google Search (BeautifulSoup4 + Requests)
    # 1. Check robots.txt
    # 2. Construct search queries
    # 3. Scrape with proper delays
    # 4. Extract structured data
    # 5. Store with source attribution

Information to Collect:
Name and Title
Current Position
Department/Affiliation
Education History
Contact Information
Research Interests
Biography
Awards/Honors
Professional Memberships

Display the Data
create a pdf version of the data

NOTES:
for each information, cite where it came from
for listing the papers and their keywords, go from recent to oldest